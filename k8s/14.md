# Lab 14: Kubernetes StatefulSet

## Task 1: Implement StatefulSet in Helm Chart

In this task I've renamed `deployment.yml` to `statefulset.yml`, created a manifest for `StatefulSet` following the
tutorial, moved values to variables in values.yml.

```yaml
PS C:\Users\Vladi\PycharmProjects\S25-core-course-labs\k8s> helm install --dry-run --debug python-app .\python-app\

NAME: python-app
LAST DEPLOYED: Sat Mar 15 11:43:47 2025
NAMESPACE: default
STATUS: pending-install
REVISION: 1
USER-SUPPLIED VALUES:
  { }

COMPUTED VALUES:
PASSWORD: supersecurepassword
affinity: { }
autoscaling:
  enabled: false
  maxReplicas: 100
  minReplicas: 1
  targetCPUUtilizationPercentage: 80
config:
  path: files/config.json
env:
  ENV: default
fullnameOverride: ""
image:
  pullPolicy: IfNotPresent
  repository: vladis7love/app_python
  tag: latest
imagePullSecrets: [ ]
ingress:
  annotations: { }
  className: ""
  enabled: false
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: [ ]
livenessProbe:
  httpGet:
    path: /
    port: http
mylibchart:
  global: { }
nameOverride: ""
nodeSelector: { }
podAnnotations:
  vault.hashicorp.com/agent-inject: "true"
  vault.hashicorp.com/agent-inject-secret-database-config.txt: internal/data/database/config
  vault.hashicorp.com/role: python-app
podLabels: { }
podManagementPolicy: Parallel
podSecurityContext: { }
readinessProbe:
  httpGet:
    path: /
    port: http
replicaCount: 5
resources:
  limits:
    cpu: 100m
    memory: 128Mi
  requests:
    cpu: 100m
    memory: 128Mi
securityContext: { }
service:
  port: 5000
  type: ClusterIP
serviceAccount:
  annotations: { }
  automount: true
  create: true
  name: ""
tolerations: [ ]
volumeClaimTemplates:
  name: python-app-visits-data-dev
  storage: 128Mi
volumeMounts:
  - mountPath: /app/data
    name: python-app-visits-data-dev
volumes: null

HOOKS:
---
# Source: python-app/templates/post-install-hook.yml
apiVersion: v1
kind: Pod
metadata:
  name: postinstall-hook
  annotations:
    "helm.sh/hook": "post-install"
    "helm.sh/hook-delete-policy": "hook-succeeded"
spec:
  containers:
    - name: post-install-container
      image: busybox
      imagePullPolicy: Always
      command: [ "sleep", "20" ]
  restartPolicy: Never
---
# Source: python-app/templates/pre-install-hook.yml
apiVersion: v1
kind: Pod
metadata:
  name: preinstall-hook
  annotations:
    "helm.sh/hook": "pre-install"
    "helm.sh/hook-delete-policy": "hook-succeeded"
spec:
  containers:
    - name: pre-install-container
      image: busybox
      imagePullPolicy: IfNotPresent
      command: [ "sleep", "20" ]
  restartPolicy: Never
---
# Source: python-app/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "python-app-test-connection"
  labels:
    helm.sh/chart: python-app-0.1.0
    app.kubernetes.io/name: python-app
    app.kubernetes.io/instance: python-app
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: wget
      image: busybox
      command: [ 'wget' ]
      args: [ 'python-app:5000' ]
  restartPolicy: Never
MANIFEST:
---
# Source: python-app/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: python-app
  labels:
    helm.sh/chart: python-app-0.1.0
    app.kubernetes.io/name: python-app
    app.kubernetes.io/instance: python-app
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
automountServiceAccountToken: true
---
# Source: python-app/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: python-app
  labels:
    helm.sh/chart: python-app-0.1.0
    app.kubernetes.io/name: python-app
    app.kubernetes.io/instance: python-app
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 5000
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: python-app
    app.kubernetes.io/instance: python-app
---
# Source: python-app/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: python-app
  labels:
    helm.sh/chart: python-app-0.1.0
    app.kubernetes.io/name: python-app
    app.kubernetes.io/instance: python-app
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: python-app
spec:
  podManagementPolicy: Parallel
  serviceName: python-app
  replicas: 5
  selector:
    matchLabels:
      app.kubernetes.io/name: python-app
      app.kubernetes.io/instance: python-app
      app.kubernetes.io/version: "1.16.0"
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/instance: python-app
  volumeClaimTemplates:
    - metadata:
        name: python-app-visits-data-dev
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: 128Mi
  template:
    metadata:
      annotations:
        vault.hashicorp.com/agent-inject: "true"
        vault.hashicorp.com/agent-inject-secret-database-config.txt: internal/data/database/config
        vault.hashicorp.com/role: python-app
      labels:
        helm.sh/chart: python-app-0.1.0
        app.kubernetes.io/name: python-app
        app.kubernetes.io/instance: python-app
        app.kubernetes.io/version: "1.16.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/version: "1.16.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/instance: python-app
    spec:
      serviceAccountName: python-app
      containers:
        - name: python-app
          image: "vladis7love/app_python:latest"
          imagePullPolicy: IfNotPresent
          env:


            - name: PASSWORD
              value: "supersecurepassword"

          ports:
            - name: http
              containerPort: 5000
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /
              port: http
          readinessProbe:
            httpGet:
              path: /
              port: http
          resources:
            limits:
              cpu: 100m
              memory: 128Mi
            requests:
              cpu: 100m
              memory: 128Mi
          volumeMounts:
            - mountPath: /app/data
              name: python-app-visits-data-dev
```

I've deployed app

```bash
PS C:\Users\Vladi\PycharmProjects\S25-core-course-labs\k8s> helm install python-app .\python-app\                  
NAME: python-app
LAST DEPLOYED: Sat Mar 15 11:53:22 2025
NAMESPACE: default
STATUS: deployed
REVISION: 1
NOTES:
1. Get the application URL by running these commands:
  export POD_NAME=$(kubectl get pods --namespace default -l "app.kubernetes.io/name=python-app,app.kubernetes.io/instance=python-app" -o jsonpath="{.items[0].metadata.name}")  
  export CONTAINER_PORT=$(kubectl get pod --namespace default $POD_NAME -o jsonpath="{.spec.containers[0].ports[0].containerPort}")
  echo "Visit http://127.0.0.1:8080 to use your application"
  kubectl --namespace default port-forward $POD_NAME 8080:$CONTAINER_PORT
```

## Task 2: StatefulSet Exploration and Optimization

### 1.Research and Documentation

```bash
PS C:\Users\Vladi\PycharmProjects\S25-core-course-labs\k8s> kubectl get po,sts,svc,pvc
NAME               READY   STATUS    RESTARTS      AGE
pod/python-app-0   1/1     Running   0             91s
pod/python-app-1   1/1     Running   0             91s
pod/python-app-2   1/1     Running   0             91s
pod/python-app-3   1/1     Running   0             91s

NAME                          READY   AGE
statefulset.apps/python-app   4/4     91s

NAME                               TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE
service/kubernetes                 ClusterIP   10.96.0.1        <none>        443/TCP             18d
service/python-app                 ClusterIP   10.101.75.167    <none>        5000/TCP            91s

NAME                                                            STATUS   VOLUME         
                            CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
persistentvolumeclaim/python-app-visits-data-dev-python-app-0   Bound    pvc-4c7418e3-ba65-40ba-b92f-9bed2eb27666   128Mi      RWO            standard       <unset>            
     91s
persistentvolumeclaim/python-app-visits-data-dev-python-app-1   Bound    pvc-2775175e-ccc4-4edc-99a1-9debdab8aaa5   128Mi      RWO            standard       <unset>            
     91s
persistentvolumeclaim/python-app-visits-data-dev-python-app-2   Bound    pvc-e9d7e5f6-3ef6-4b26-b6d2-05edaee45fb9   128Mi      RWO            standard       <unset>            
     91s
persistentvolumeclaim/python-app-visits-data-dev-python-app-3   Bound    pvc-b70011d8-4c6f-4af4-a564-05358abe7144   128Mi      RWO            standard       <unset>            
     91s
```

```bash
PS C:\Users\Vladi\PycharmProjects\S25-core-course-labs\k8s> minikube service python-app
|-----------|------------|-------------|--------------|
| NAMESPACE |    NAME    | TARGET PORT |     URL      |
|-----------|------------|-------------|--------------|
| default   | python-app |             | No node port |
|-----------|------------|-------------|--------------|
* service default/python-app has no node port
! Services [default/python-app] have type "ClusterIP" not meant to be exposed, however for local development minikube allows you to access this !
* Starting tunnel for service python-app.
|-----------|------------|-------------|------------------------|
| NAMESPACE |    NAME    | TARGET PORT |          URL           |
|-----------|------------|-------------|------------------------|
| default   | python-app |             | http://127.0.0.1:57164 |
|-----------|------------|-------------|------------------------|
* Opening service default/python-app in default browser...
```

We can check the content of file `visits.txt` in each pod, kubectl exec ... -- cat visits.txt, and provide the output
for all replicas.

```bash
PS C:\Users\Vladi\PycharmProjects\S25-core-course-labs\app_python> kubectl exec python-app-0 exec -- cat data/visits.txt
193
PS C:\Users\Vladi\PycharmProjects\S25-core-course-labs\app_python> kubectl exec python-app-2 exec -- cat data/visits.txt
152
PS C:\Users\Vladi\PycharmProjects\S25-core-course-labs\app_python> kubectl exec python-app-1 exec -- cat data/visits.txt
174
PS C:\Users\Vladi\PycharmProjects\S25-core-course-labs\app_python> kubectl exec python-app-3 exec -- cat data/visits.txt
131
```

The different values in each replica suggest that each Pod is maintaining its own state, and they are not sharing this
file or data.
This is typical behavior when each Pod in a StatefulSet manages its own persistent volume or data, and that data is not
replicated across Pods unless explicitly configured, so we have different values due to load balancing

### 2.Persistent Storage Validation

After pod deletion, the PVC still remains alive. And data inside 'visits.txt' from the pod will be equal data before the
deletion.

```bash
PS C:\Users\Vladi\PycharmProjects\S25-core-course-labs\app_python> kubectl delete pod python-app-0
pod "python-app-0" deleted

PS C:\Users\Vladi\PycharmProjects\S25-core-course-labs\app_python> kubectl exec python-app-0 -- cat data/visits.txt
193


PS C:\Users\Vladi\PycharmProjects\S25-core-course-labs\app_python> kubectl get po,svc   
NAME               READY   STATUS    RESTARTS       AGE
pod/python-app-0   1/1     Running   0              2m
pod/python-app-1   1/1     Running   0              42m
pod/python-app-2   1/1     Running   0              42m
pod/python-app-3   1/1     Running   0              42m
pod/vault-0        1/1     Running   1 (143m ago)   43h

NAME                               TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE
service/js-app                     ClusterIP   10.110.1.244     <none>        8080/TCP            7d16h
201/TCP   8d
service/vault-agent-injector-svc   ClusterIP   10.102.244.18    <none>        443/TCP             8d
service/vault-internal             ClusterIP   None             <none>        8200/TCP,8201/TCP   8d
```

### 3.Headless Service Access

Pods were able to resolve each other's DNS names, demonstrating stable network identities

```bash
PS C:\Users\Vladi\PycharmProjects\S25-core-course-labs\k8s> kubectl exec python-app-0 -- getent hosts python-app-1.python-app
10.244.1.50     python-app-1.python-app.default.svc.cluster.local
PS C:\Users\Vladi\PycharmProjects\S25-core-course-labs\k8s> kubectl exec python-app-1 -- getent hosts python-app-2.python-app
10.244.1.49     python-app-2.python-app.default.svc.cluster.local
PS C:\Users\Vladi\PycharmProjects\S25-core-course-labs\k8s> kubectl exec python-app-2 -- getent hosts python-app-3.python-app
10.244.1.51     python-app-3.python-app.default.svc.cluster.local
```

### 4.Monitoring & Alerts

```yaml
livenessProbe:
  httpGet:
    path: /
    port: http
readinessProbe:
  httpGet:
    path: /
    port: http
```

- The `liveness probe` checks whether your application is still running and healthy. If the probe fails, Kubernetes will
  restart the pod automatically.
- The `readiness probe` determines if the pod is ready to handle traffic. If the probe fails, Kubernetes will stop
  sending
  traffic to that pod, even though it may still be running. Similar to the liveness probe, it checks if the pod's HTTP
  service is up and can serve requests. If it fails, the pod won't receive any traffic until it passes the readiness
  check.

For stateful applications, which maintain data or session consistency, probes help avoid traffic loss, ensure smooth
failover, and prevent data corruption by only routing traffic to healthy pods. This automatic monitoring and recovery
mechanism is vital for maintaining the integrity and availability of stateful services.

### 5.Ordering Guarantee and Parallel Operations

Ordering guarantees are unnecessary for my app because each pod operates independently, with its own Persistent Volume
Claim (PVC).

- There is no dependency between the pods during startup or shutdown, meaning the order in which pods are
  launched or terminated doesn't affect the application's functionality.
- The system is designed to handle parallel operations across pods without issues.

To enable parallel operations, the `podManagementPolicy: Parallel` configuration was used. This instructs the
StatefulSet
controller to launch or terminate all pods in parallel, rather than one by one, optimizing the deployment and scaling
process.

## Bonus Task: Update Strategies

The same steps were implemented for bonus app:

```bash
PS C:\Users\Vladi\PycharmProjects\S25-core-course-labs\k8s> helm install js-app .\js-app\        
NAME: js-app
LAST DEPLOYED: Sat Mar 15 14:44:00 2025
NAMESPACE: default
STATUS: deployed
REVISION: 1
NOTES:
1. Get the application URL by running these commands:
  export POD_NAME=$(kubectl get pods --namespace default -l "app.kubernetes.io/name=js-app,app.kubernetes.io/instance=js-app" -o jsonpath="{.items[0].metadata.name}")
  export CONTAINER_PORT=$(kubectl get pod --namespace default $POD_NAME -o jsonpath="{.spec.containers[0].ports[0].containerPort}")
  echo "Visit http://127.0.0.1:8080 to use your application"
  kubectl --namespace default port-forward $POD_NAME 8080:$CONTAINER_PORT

PS C:\Users\Vladi\PycharmProjects\S25-core-course-labs\k8s> kubectl get po,sts,svc,pvc
NAME               READY   STATUS    RESTARTS       AGE
pod/js-app-0       1/1     Running   0              97s
pod/js-app-1       1/1     Running   0              97s
pod/js-app-2       1/1     Running   0              97s

NAME                          READY   AGE
statefulset.apps/js-app       3/3     98s

NAME                               TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE
service/js-app                     ClusterIP   10.110.1.244     <none>        8080/TCP            7d17h
service/kubernetes                 ClusterIP   10.96.0.1        <none>        443/TCP             18d

NAME                                                            STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
persistentvolumeclaim/js-app-visits-data-dev-js-app-0           Bound    pvc-609a7503-4fbd-4869-9b98-35322410b5bb   512Mi      RWO            standard       <unset>                 97s
persistentvolumeclaim/js-app-visits-data-dev-js-app-1           Bound    pvc-366ca84f-d913-4ffc-8aea-6333f34039a2   512Mi      RWO            standard       <unset>                 97s
persistentvolumeclaim/js-app-visits-data-dev-js-app-2           Bound    pvc-706e2c15-4c5c-4b0b-b64f-bcad9158772c   512Mi      RWO            standard       <unset>                 97s
```

```yaml
spec:
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 1
```

OnDelete:

- Requires manual pod deletion to apply updates.
- Use for stateful apps needing controlled updates, like databases.

RollingUpdate:

- Updates pods one by one, maintaining identity and avoiding downtime.
- Use for stateful apps needing zero-downtime updates, like distributed databases.

Deployment Update Strategies:

- RollingUpdate: Like in StatefulSets, but for stateless apps where pods can be freely replaced.
- Recreate: Terminates all pods before creating new ones, causing downtime, but useful when a full reset is needed.

❗Key Difference: `StatefulSets` maintain pod identity and state, making them ideal for stateful applications, while
`Deployments` are best for stateless apps.

In `StatefulSets`, OnDelete gives manual control over pod updates, while
RollingUpdate ensures a more automated and controlled update process. For `Deployments`, the update strategies are
primarily RollingUpdate (default) and Recreate, focusing on availability and downtime during updates.
